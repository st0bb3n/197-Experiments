{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ToPass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Requirements"
      ],
      "metadata": {
        "id": "dN2vZC7C5W77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==0.4.6\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install pycocotools\n",
        "!pip install cpython\n",
        "!pip install wget\n",
        "!git clone https://github.com/pytorch/vision"
      ],
      "metadata": {
        "id": "IHUTJH-hNhNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Dataset pathing and torchvision reference modules"
      ],
      "metadata": {
        "id": "Wr7EMccW5u1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/vision/references/detection\")\n",
        "\n",
        "dataset_path = \"/content/drinkscoco\""
      ],
      "metadata": {
        "id": "_HOJdCZLvsDF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset"
      ],
      "metadata": {
        "id": "FkFP9gJxrTlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "import shutil\n",
        "\n",
        "url = \"https://github.com/st0bb3n/ObjectDetection-Drinks/releases/download/Dataset/drinkscoco.zip\"\n",
        "x = wget.download(url, \"data.zip\")\n",
        "\n",
        "shutil.unpack_archive(\"data.zip\",\"drinkscoco\")"
      ],
      "metadata": {
        "id": "6hz3eyeOFETG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main function + Dataset Class. To be run first."
      ],
      "metadata": {
        "id": "krf0KQGB64ko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mesUuEtNd7c"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from torchvision.transforms import functional as FT\n",
        "from torchvision import transforms as T\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split, Dataset\n",
        "import copy\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A  # our data augmentation library\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import time\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from pycocotools.coco import COCO\n",
        "#from albumentations.pytorch import ToTensorV2\n",
        "from engine import evaluate, train_one_epoch\n",
        "import utils\n",
        "\n",
        "class Drinks(datasets.VisionDataset):\n",
        "    def __init__(self, root, split='train', transform=None, target_transform=None, transforms=None):\n",
        "        # the 3 transform parameters are required for datasets.VisionDataset\n",
        "        super().__init__(root, transforms, transform, target_transform)\n",
        "        self.split = split #train, valid, test\n",
        "        self.coco = COCO(os.path.join(root, split, \"_annotations.coco.json\")) # annotations stored here\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "        self.ids = [id for id in self.ids if (len(self._load_target(id)) > 0)]\n",
        "    \n",
        "    def _load_image(self, id: int):\n",
        "        path = self.coco.loadImgs(id)[0]['file_name']\n",
        "        image = cv2.imread(os.path.join(self.root, self.split, path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "\n",
        "        return image/255\n",
        "\n",
        "    def _load_target(self, id):\n",
        "        return self.coco.loadAnns(self.coco.getAnnIds(id))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        id = self.ids[index]\n",
        "        image = self._load_image(id)\n",
        "        target = self._load_target(id)\n",
        "        target = copy.deepcopy(self._load_target(id))\n",
        "        \n",
        "        boxes = [t['bbox'] + [t['category_id']] for t in target] \n",
        "        \n",
        "        new_boxes = [] # convert from xywh to xyxy\n",
        "        for box in boxes:\n",
        "            xmin = box[0]\n",
        "            xmax = xmin + box[2]\n",
        "            ymin = box[1]\n",
        "            ymax = ymin + box[3]\n",
        "            new_boxes.append([xmin, ymin, xmax, ymax])\n",
        "        \n",
        "        boxes = torch.tensor(new_boxes, dtype=torch.float32)\n",
        "        \n",
        "        targ = {} # here is our transformed target\n",
        "        targ['boxes'] = boxes\n",
        "        targ['labels'] = torch.tensor([t['category_id'] for t in target], dtype=torch.int64)\n",
        "        #targ['image_id'] = torch.tensor([t['image_id'] for t in target])\n",
        "        targ['image_id'] = torch.tensor([index])\n",
        "        targ['area'] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) # we have a different area\n",
        "        targ['iscrowd'] = torch.tensor([t['iscrowd'] for t in target], dtype=torch.int64)\n",
        "        \n",
        "        return torchvision.transforms.ToTensor()(image), targ # scale images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test.py"
      ],
      "metadata": {
        "id": "gqIxpt7fW6h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coco = COCO(os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"))\n",
        "categories = coco.cats\n",
        "n_classes = len(categories.keys())\n",
        "classes = [i[1]['name'] for i in categories.items()]\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)\n",
        "\n",
        "train_dataset = Drinks(root=dataset_path, transforms=torchvision.transforms.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=utils.collate_fn)\n",
        "\n",
        "images,targets = next(iter(train_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k:v for k, v in t.items()} for t in targets]\n",
        "output = model(images, targets)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)\n",
        "\n",
        "dataset = Drinks(root=dataset_path, transforms=torchvision.transforms.ToTensor())\n",
        "test_dataset = Drinks(root=dataset_path, split=\"test\", transforms=torchvision.transforms.ToTensor())\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=2, shuffle=True, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=1, shuffle=False, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "evaluate(model, data_loader_test, device=device)"
      ],
      "metadata": {
        "id": "BmTRT9vBW045"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.py"
      ],
      "metadata": {
        "id": "_G2LTYfjW92o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coco = COCO(os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"))\n",
        "categories = coco.cats\n",
        "n_classes = len(categories.keys())\n",
        "classes = [i[1]['name'] for i in categories.items()]\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features # we need to change the head\n",
        "model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)\n",
        "\n",
        "train_dataset = Drinks(root=dataset_path, transforms=torchvision.transforms.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=utils.collate_fn)\n",
        "\n",
        "images,targets = next(iter(train_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k:v for k, v in t.items()} for t in targets]\n",
        "#output = model(images, targets)\n",
        "output = model(images, targets)\n",
        "device = torch.device(\"cuda\") # use GPU to train\n",
        "model = model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)\n",
        "\n",
        "dataset = Drinks(root=dataset_path, transforms=torchvision.transforms.ToTensor())\n",
        "test_dataset = Drinks(root=dataset_path, split=\"test\", transforms=torchvision.transforms.ToTensor())\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=2, shuffle=True, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=1, shuffle=False, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "num_epochs=10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=50)\n",
        "    #lr_scheduler.step()\n",
        "    evaluate(model, data_loader_test, device=device)\n",
        "    \n",
        "model.eval()\n",
        "torch.save(model.state_dict(), \"trainedmodel.pth\")\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "veFmo_rRQDoM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}